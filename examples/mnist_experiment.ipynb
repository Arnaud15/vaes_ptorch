{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b40a331-59dc-40fe-99a1-65a5fb5c3f99",
   "metadata": {},
   "source": [
    "## VAEs on MNIST - Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25463372-50d4-4141-bee5-9d0b58fae335",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7321b105-99ae-49b5-9b2e-c10ea7056d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tdata\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from vaes_ptorch import GaussianModel, GaussianVAE, TrainArgs, get_mlp, train\n",
    "from vaes_ptorch.args import DivAnnealing\n",
    "from vaes_ptorch.losses import Likelihood\n",
    "from vaes_ptorch.train_vae import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c3ef0-0690-4cce-91e5-f7e4b9ae2ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "420fb653-9030-4fcc-82d4-2851d188dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_repeats = 2\n",
    "learning_rates = 10 ** np.linspace(start=-4.0, stop=-2.0, num=2)\n",
    "divergence_scales = 10 ** np.linspace(start=-2.0, stop=3.0, num=2)\n",
    "\n",
    "info_vae = False\n",
    "\n",
    "latent_dim = 12\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 128\n",
    "eval_share = 0.7\n",
    "\n",
    "base_args = TrainArgs(\n",
    "    likelihood=Likelihood.Bernoulli,\n",
    "    info_vae=info_vae,\n",
    "    num_epochs=num_epochs,\n",
    "    div_annealing=DivAnnealing(\n",
    "        start_epochs=1, linear_epochs=1, start_scale=0.0, end_scale=0.0,\n",
    "    ),\n",
    "    print_every=0,\n",
    "    eval_every=1,\n",
    "    smoothing=0.9,\n",
    ")\n",
    "\n",
    "use_gpu = True\n",
    "device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae2c5f-ffaa-4e50-be21-44bca1e17efd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15ae877-82e9-4045-9086-120e91693040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(x):\n",
    "    \"\"\"Converts grayscale pixel values in [0, 1] to binary data in {0, 1}.\"\"\"\n",
    "    tensor = T.ToTensor()(x)\n",
    "    mask = tensor > 0.5\n",
    "    tensor[mask] = 1.0\n",
    "    tensor[~mask] = 0.0\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_data(batch_size: int, eval_share: float):\n",
    "    dataset = torchvision.datasets.MNIST(\n",
    "        root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=binarize,\n",
    "    )\n",
    "    train_size = int(len(dataset) * eval_share)\n",
    "    eval_size = len(dataset) - train_size\n",
    "    train_data, eval_data = tdata.random_split(\n",
    "        dataset,\n",
    "        [train_size, eval_size],\n",
    "        generator=torch.Generator().manual_seed(15),\n",
    "    )\n",
    "    train_loader = tdata.DataLoader(\n",
    "        dataset=train_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    eval_loader = tdata.DataLoader(\n",
    "        dataset=eval_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_set = torchvision.datasets.MNIST(\n",
    "        root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=binarize,\n",
    "    )\n",
    "    test_loader = tdata.DataLoader(\n",
    "        dataset=test_set, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    print(f\"Train size: {train_size}, Eval size: {eval_size}\")\n",
    "    return train_loader, eval_loader, test_loader\n",
    "\n",
    "\n",
    "def build_vae(device, latent_dim):\n",
    "    encoder = GaussianModel(\n",
    "        model=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            get_mlp(in_dim=28 * 28, out_dim=2 * latent_dim, h_dims=[512] * 3),\n",
    "        ),\n",
    "        out_dim=latent_dim,\n",
    "        min_var=1e-10,\n",
    "    )\n",
    "    decoder = GaussianModel(\n",
    "        model=nn.Sequential(\n",
    "            get_mlp(in_dim=latent_dim, out_dim=2 * 28 * 28, h_dims=[512] * 3),\n",
    "            nn.Unflatten(1, (2, 28, 28)),\n",
    "        ),\n",
    "        out_dim=1,\n",
    "        split_dim=1,\n",
    "    )\n",
    "    vae = GaussianVAE(encoder=encoder, decoder=decoder)\n",
    "    vae = vae.to(device)\n",
    "    return vae\n",
    "\n",
    "\n",
    "def get_params(scale: float):\n",
    "    annealing_params = vars(base_args.div_annealing)\n",
    "    annealing_params[\"end_scale\"] = scale\n",
    "    del annealing_params[\"epoch\"]\n",
    "    params = vars(base_args)\n",
    "    params[\"div_annealing\"] = DivAnnealing(**annealing_params)\n",
    "    args = TrainArgs(**params)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2255bd7-0aea-4803-94e2-7dda528a02bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8dc2a-76f2-46d4-a980-4aa14791cbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud15/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630778054/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 42000, Eval size: 18000\n",
      "ELBO at the end of epoch #1 is 165.61446\n",
      "ELBO at the end of epoch #2 is 133.95690\n",
      "ELBO at the end of epoch #3 is 114.16067\n",
      "ELBO at the end of epoch #1 is 171.84254\n",
      "ELBO at the end of epoch #2 is 126.70070\n",
      "ELBO at the end of epoch #3 is 111.06838\n",
      "ELBO at the end of epoch #1 is 137.56675\n",
      "ELBO at the end of epoch #2 is 157.35011\n",
      "ELBO at the end of epoch #3 is 146.31366\n",
      "ELBO at the end of epoch #1 is 175.53107\n",
      "ELBO at the end of epoch #2 is 166.69402\n",
      "ELBO at the end of epoch #3 is 166.55007\n",
      "ELBO at the end of epoch #1 is 170.74951\n",
      "ELBO at the end of epoch #2 is 206.93230\n",
      "ELBO at the end of epoch #3 is 206.46890\n",
      "ELBO at the end of epoch #1 is 207.08602\n",
      "ELBO at the end of epoch #2 is 206.52991\n",
      "ELBO at the end of epoch #3 is 206.37646\n",
      "ELBO at the end of epoch #1 is 124.14252\n",
      "ELBO at the end of epoch #2 is 207.23155\n",
      "ELBO at the end of epoch #3 is 206.55199\n",
      "ELBO at the end of epoch #1 is 206.62069\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "train_loader, eval_loader, test_loader = get_data(\n",
    "    batch_size=batch_size, eval_share=eval_share\n",
    ")\n",
    "for scale in divergence_scales:\n",
    "    min_error = float(\"inf\")\n",
    "    for lr in learning_rates:\n",
    "        args = get_params(scale)\n",
    "        eval_errors = []\n",
    "        for _ in range(num_repeats):\n",
    "            vae = build_vae(device, latent_dim)\n",
    "            optimizer = torch.optim.Adam(params=vae.parameters(), lr=lr)\n",
    "            eval_errors.append(\n",
    "                train(\n",
    "                    train_data=train_loader,\n",
    "                    vae=vae,\n",
    "                    optimizer=optimizer,\n",
    "                    args=args,\n",
    "                    eval_data=eval_loader,\n",
    "                    device=device,\n",
    "                ).eval_ewma\n",
    "            )\n",
    "        avg_error = sum(eval_errors) / len(eval_errors)\n",
    "        if avg_error < min_error:\n",
    "            min_error = avg_error\n",
    "            best_vae = vae\n",
    "            best_args = args\n",
    "    error = evaluate(test_loader, best_vae, args=best_args, device=device)\n",
    "    errors.append(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
