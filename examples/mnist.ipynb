{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b40a331-59dc-40fe-99a1-65a5fb5c3f99",
   "metadata": {},
   "source": [
    "## VAEs on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25463372-50d4-4141-bee5-9d0b58fae335",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7321b105-99ae-49b5-9b2e-c10ea7056d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as tdata\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from vaes_ptorch import (\n",
    "    CNN,\n",
    "    DeCNN,\n",
    "    GaussianModel,\n",
    "    GaussianVAE,\n",
    "    TrainArgs,\n",
    "    get_mlp,\n",
    "    train,\n",
    ")\n",
    "from vaes_ptorch.args import DivAnnealing\n",
    "from vaes_ptorch.losses import Likelihood\n",
    "from vaes_ptorch.train_vae import evaluate\n",
    "from vaes_ptorch.utils import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c3ef0-0690-4cce-91e5-f7e4b9ae2ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdac4160-0941-462e-8aa5-762c78315524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "latent_dim = 12\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "print_every = 0\n",
    "eval_every = 5\n",
    "\n",
    "likelihood = Likelihood.Bernoulli\n",
    "# info_vae = True\n",
    "info_vae = False\n",
    "start_scale = 0\n",
    "end_scale = 0\n",
    "# start_scale = 500.0\n",
    "# end_scale = 500.0\n",
    "start_epochs = 0\n",
    "linear_epochs = 0\n",
    "\n",
    "in_channels = 1\n",
    "kernel_sizes = [\n",
    "    5,\n",
    "    5,\n",
    "    3,\n",
    "    3,\n",
    "]\n",
    "downsampling = [\n",
    "    True,  # 14\n",
    "    False,  # 14\n",
    "    True,  # 7\n",
    "    False,  # 7\n",
    "]\n",
    "out_channels = [\n",
    "    16,\n",
    "    16,\n",
    "    32,\n",
    "    32,\n",
    "]\n",
    "rev_out_channels = [\n",
    "    32,\n",
    "    16,\n",
    "    16,\n",
    "    1,\n",
    "]\n",
    "rev_downsampling = [\n",
    "    False,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "]\n",
    "rev_kernel_sizes = [\n",
    "    5,\n",
    "    5,\n",
    "    3,\n",
    "    3,\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae2c5f-ffaa-4e50-be21-44bca1e17efd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7586605-1ffd-4c67-b83a-321a72f5984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 42000, Eval size: 18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud15/miniconda3/envs/ptorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630778054/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "def binarize(x):\n",
    "    \"\"\"Converts grayscale pixel values in [0, 1] to binary data in {0, 1}.\"\"\"\n",
    "    tensor = T.ToTensor()(x)\n",
    "    mask = tensor > 0.5\n",
    "    tensor[mask] = 1.0\n",
    "    tensor[~mask] = 0.0\n",
    "    return tensor\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=binarize,\n",
    ")\n",
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "eval_size = len(dataset) - train_size\n",
    "train_data, eval_data = tdata.random_split(\n",
    "    dataset,\n",
    "    [train_size, eval_size],\n",
    "    generator=torch.Generator().manual_seed(15),\n",
    ")\n",
    "\n",
    "train_loader = tdata.DataLoader(\n",
    "    dataset=train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "eval_loader = tdata.DataLoader(\n",
    "    dataset=eval_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=binarize,\n",
    ")\n",
    "test_loader = tdata.DataLoader(\n",
    "    dataset=test_set, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "### COMMENT OUT THE BELOW 2 LINES FOR ACTUAL EVALUATION\n",
    "# test_loader = train_loader\n",
    "# eval_loader = train_loader\n",
    "print(f\"Train size: {train_size}, Eval size: {eval_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad7de1-1ac8-40f3-b976-4c7bd148f3a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Setting up the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b8b945-0b3a-4b46-a655-4ae6b49145c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GaussianModel(\n",
    "    model=nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        get_mlp(in_dim=28 * 28, out_dim=2 * latent_dim, h_dims=[512] * 3),\n",
    "    ),\n",
    "    out_dim=latent_dim,\n",
    "    min_var=1e-10,\n",
    ")\n",
    "decoder = GaussianModel(\n",
    "    model=nn.Sequential(\n",
    "        get_mlp(in_dim=latent_dim, out_dim=2 * 28 * 28, h_dims=[512] * 3),\n",
    "        nn.Unflatten(1, (2, 28, 28)),\n",
    "    ),\n",
    "    out_dim=1,\n",
    "    split_dim=1,\n",
    ")\n",
    "vae = GaussianVAE(encoder=encoder, decoder=decoder)\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1388aff-b6db-4c01-93c2-2c83a1099144",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Initializing the optimizer and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb889b6-0d60-4f70-a9c3-439a364bca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=vae.parameters(), lr=lr)\n",
    "\n",
    "train_args = TrainArgs(\n",
    "    likelihood=likelihood,\n",
    "    info_vae=info_vae,\n",
    "    num_epochs=num_epochs,\n",
    "    div_annealing=DivAnnealing(\n",
    "        start_epochs=start_epochs,\n",
    "        linear_epochs=linear_epochs,\n",
    "        start_scale=start_scale,\n",
    "        end_scale=end_scale,\n",
    "    ),\n",
    "    print_every=print_every,\n",
    "    eval_every=eval_every,\n",
    "    smoothing=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2255bd7-0aea-4803-94e2-7dda528a02bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8dc2a-76f2-46d4-a980-4aa14791cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    train_data=train_loader,\n",
    "    vae=vae,\n",
    "    optimizer=optimizer,\n",
    "    args=train_args,\n",
    "    eval_data=eval_loader,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d276e-7799-479e-8d3c-112dc66d636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_loader, vae, args=train_args, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d0f2-c413-4dda-9f86-d8f94ef45801",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = next(iter(test_loader))[0][:16].to(device)\n",
    "show(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639453b-d606-4e52-b7df-bc23e82b3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = vae(input_images)\n",
    "show(nn.Sigmoid()(reconstructed_images.mu_x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
