{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b40a331-59dc-40fe-99a1-65a5fb5c3f99",
   "metadata": {},
   "source": [
    "## VAEs on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25463372-50d4-4141-bee5-9d0b58fae335",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7321b105-99ae-49b5-9b2e-c10ea7056d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from vaes_ptorch import (\n",
    "    CNN,\n",
    "    DeCNN,\n",
    "    GaussianModel,\n",
    "    GaussianVAE,\n",
    "    TrainArgs,\n",
    "    get_mlp,\n",
    "    train,\n",
    ")\n",
    "from vaes_ptorch.args import DivAnnealing\n",
    "from vaes_ptorch.train_vae import evaluate\n",
    "from vaes_ptorch.utils import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c3ef0-0690-4cce-91e5-f7e4b9ae2ac6",
   "metadata": {},
   "source": [
    "#### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdac4160-0941-462e-8aa5-762c78315524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "latent_dim = 120\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 3\n",
    "\n",
    "print_every = 50\n",
    "eval_every = 1\n",
    "\n",
    "info_vae = True\n",
    "# info_vae = False\n",
    "# start_scale = 50.0\n",
    "# end_scale = 50.0\n",
    "start_scale = 1.0\n",
    "end_scale = 1.0\n",
    "start_epochs = 0\n",
    "linear_epochs = 0\n",
    "\n",
    "in_channels = 1\n",
    "kernel_sizes = [\n",
    "    5,\n",
    "    5,\n",
    "    5,\n",
    "    5,\n",
    "]\n",
    "downsampling = [\n",
    "    True,  # 14\n",
    "    False,  # 14\n",
    "    True,  # 7\n",
    "    False,  # 7\n",
    "]\n",
    "out_channels = [\n",
    "    8,\n",
    "    8,\n",
    "    16,\n",
    "    16,\n",
    "]\n",
    "rev_out_channels = [\n",
    "    16,\n",
    "    8,\n",
    "    8,\n",
    "    2,\n",
    "]\n",
    "rev_downsampling = [\n",
    "    False,\n",
    "    True,\n",
    "    False,\n",
    "    True,\n",
    "]\n",
    "rev_kernel_sizes = [\n",
    "    5,\n",
    "    5,\n",
    "    5,\n",
    "    5,\n",
    "]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae2c5f-ffaa-4e50-be21-44bca1e17efd",
   "metadata": {},
   "source": [
    "#### Getting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7586605-1ffd-4c67-b83a-321a72f5984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.ToTensor(),\n",
    ")\n",
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "eval_size = len(dataset) - train_size\n",
    "train_data, eval_data = tdata.random_split(\n",
    "    dataset,\n",
    "    [train_size, eval_size],\n",
    "    generator=torch.Generator().manual_seed(15),\n",
    ")\n",
    "\n",
    "train_loader = tdata.DataLoader(\n",
    "    dataset=train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "eval_loader = tdata.DataLoader(\n",
    "    dataset=eval_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor(),\n",
    ")\n",
    "test_loader = tdata.DataLoader(\n",
    "    dataset=test_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad7de1-1ac8-40f3-b976-4c7bd148f3a9",
   "metadata": {},
   "source": [
    "#### Setting up the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71b8b945-0b3a-4b46-a655-4ae6b49145c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GaussianModel(\n",
    "    model=CNN(\n",
    "        in_channels=1,\n",
    "        out_channels=out_channels,\n",
    "        kernel_sizes=kernel_sizes,\n",
    "        downsampling=downsampling,\n",
    "        bn=True,\n",
    "        f_map_size=7,\n",
    "        out_dim=latent_dim * 2,\n",
    "    ),\n",
    "    out_dim=latent_dim,\n",
    "    min_var=1e-10,\n",
    ")\n",
    "decoder = GaussianModel(\n",
    "    model=DeCNN(\n",
    "        in_dim=latent_dim,\n",
    "        f_map_size=7,\n",
    "        channel_size=16,\n",
    "        out_channels=rev_out_channels,\n",
    "        kernel_sizes=rev_kernel_sizes,\n",
    "        downsampling=rev_downsampling,\n",
    "        bn=True,\n",
    "    ),\n",
    "    out_dim=1,\n",
    "    min_var=0.0,\n",
    "    split_dim=1,\n",
    ")\n",
    "vae = GaussianVAE(encoder=encoder, decoder=decoder)\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1388aff-b6db-4c01-93c2-2c83a1099144",
   "metadata": {},
   "source": [
    "#### Initializing the optimizer and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eb889b6-0d60-4f70-a9c3-439a364bca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=vae.parameters(), lr=lr)\n",
    "\n",
    "train_args = TrainArgs(\n",
    "    info_vae=info_vae,\n",
    "    num_epochs=num_epochs,\n",
    "    div_annealing=DivAnnealing(\n",
    "        start_epochs=start_epochs,\n",
    "        linear_epochs=linear_epochs,\n",
    "        start_scale=start_scale,\n",
    "        end_scale=end_scale,\n",
    "    ),\n",
    "    print_every=print_every,\n",
    "    eval_every=eval_every,\n",
    "    smoothing=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2255bd7-0aea-4803-94e2-7dda528a02bc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8dc2a-76f2-46d4-a980-4aa14791cbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Loss: 0.27889 | Div scale: 1.000\n",
      "NLL: 0.22497 | MMD-div: 0.05392\n",
      "Step: 50 | Loss: 0.17079 | Div scale: 1.000\n",
      "NLL: 0.14498 | MMD-div: 0.01666\n",
      "Step: 100 | Loss: 0.13520 | Div scale: 1.000\n",
      "NLL: 0.11376 | MMD-div: 0.01549\n",
      "Step: 150 | Loss: 0.10655 | Div scale: 1.000\n",
      "NLL: 0.08765 | MMD-div: 0.01664\n",
      "Step: 200 | Loss: 0.07750 | Div scale: 1.000\n",
      "NLL: 0.05475 | MMD-div: 0.01565\n",
      "Step: 250 | Loss: 0.05712 | Div scale: 1.000\n",
      "NLL: 0.03814 | MMD-div: 0.01653\n",
      "Step: 300 | Loss: 0.04639 | Div scale: 1.000\n",
      "NLL: 0.02830 | MMD-div: 0.01667\n",
      "ELBO at the end of epoch #1 is 0.02645\n",
      "Step: 350 | Loss: 0.04124 | Div scale: 1.000\n",
      "NLL: 0.02425 | MMD-div: 0.01534\n",
      "Step: 400 | Loss: 0.03764 | Div scale: 1.000\n",
      "NLL: 0.02125 | MMD-div: 0.01562\n",
      "Step: 450 | Loss: 0.03471 | Div scale: 1.000\n",
      "NLL: 0.01915 | MMD-div: 0.01529\n",
      "Step: 500 | Loss: 0.03109 | Div scale: 1.000\n",
      "NLL: 0.01518 | MMD-div: 0.01473\n",
      "Step: 550 | Loss: 0.02976 | Div scale: 1.000\n",
      "NLL: 0.01436 | MMD-div: 0.01622\n",
      "Step: 600 | Loss: 0.02908 | Div scale: 1.000\n",
      "NLL: 0.01368 | MMD-div: 0.01407\n",
      "Step: 650 | Loss: 0.02862 | Div scale: 1.000\n",
      "NLL: 0.01393 | MMD-div: 0.01597\n",
      "ELBO at the end of epoch #2 is 0.01360\n",
      "Step: 700 | Loss: 0.02904 | Div scale: 1.000\n",
      "NLL: 0.01385 | MMD-div: 0.01541\n",
      "Step: 750 | Loss: 0.02788 | Div scale: 1.000\n",
      "NLL: 0.01328 | MMD-div: 0.01419\n",
      "Step: 800 | Loss: 0.02749 | Div scale: 1.000\n",
      "NLL: 0.01284 | MMD-div: 0.01371\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    train_data=train_loader,\n",
    "    vae=vae,\n",
    "    optimizer=optimizer,\n",
    "    args=train_args,\n",
    "    eval_data=eval_loader,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9727ff-10dc-4379-b276-3b7f5e19dc64",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d276e-7799-479e-8d3c-112dc66d636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_loader, vae, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d0f2-c413-4dda-9f86-d8f94ef45801",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = next(iter(test_loader))[0][:16].to(device)\n",
    "show(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639453b-d606-4e52-b7df-bc23e82b3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = vae(input_images)\n",
    "show(reconstructed_images.mu_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
