{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b40a331-59dc-40fe-99a1-65a5fb5c3f99",
   "metadata": {},
   "source": [
    "## VAEs on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25463372-50d4-4141-bee5-9d0b58fae335",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7321b105-99ae-49b5-9b2e-c10ea7056d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from vaes_ptorch import (\n",
    "    CNN,\n",
    "    DeCNN,\n",
    "    GaussianModel,\n",
    "    GaussianVAE,\n",
    "    TrainArgs,\n",
    "    get_mlp,\n",
    "    train,\n",
    ")\n",
    "from vaes_ptorch.args import DivAnnealing\n",
    "from vaes_ptorch.train_vae import evaluate\n",
    "from vaes_ptorch.utils import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4c3ef0-0690-4cce-91e5-f7e4b9ae2ac6",
   "metadata": {},
   "source": [
    "#### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdac4160-0941-462e-8aa5-762c78315524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = True\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "\n",
    "print_every = 50\n",
    "eval_every = 1\n",
    "\n",
    "# info_vae = True\n",
    "info_vae = False\n",
    "# start_scale = 50.0\n",
    "# end_scale = 50.0\n",
    "start_scale = 0.1\n",
    "end_scale = 0.1\n",
    "start_epochs = 0\n",
    "linear_epochs = 0\n",
    "\n",
    "in_channels = 1\n",
    "kernel_sizes = [5, 5, 5,]\n",
    "out_channels = [16, 32, 64,]\n",
    "rev_out_channels = [16, 2]\n",
    "rev_kernel_sizes = [5, 5]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae2c5f-ffaa-4e50-be21-44bca1e17efd",
   "metadata": {},
   "source": [
    "#### Getting the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7586605-1ffd-4c67-b83a-321a72f5984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.ToTensor(),\n",
    ")\n",
    "\n",
    "train_size = int(len(dataset) * 0.7)\n",
    "eval_size = len(dataset) - train_size\n",
    "train_data, eval_data = tdata.random_split(\n",
    "    dataset,\n",
    "    [train_size, eval_size],\n",
    "    generator=torch.Generator().manual_seed(15),\n",
    ")\n",
    "\n",
    "train_loader = tdata.DataLoader(\n",
    "    dataset=train_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "eval_loader = tdata.DataLoader(\n",
    "    dataset=eval_data, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=os.path.expanduser(\"~/vaes_ptorch/data\"),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor(),\n",
    ")\n",
    "test_loader = tdata.DataLoader(\n",
    "    dataset=test_set, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad7de1-1ac8-40f3-b976-4c7bd148f3a9",
   "metadata": {},
   "source": [
    "#### Setting up the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71b8b945-0b3a-4b46-a655-4ae6b49145c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GaussianModel(\n",
    "    model=CNN(\n",
    "        in_channels=1,\n",
    "        out_channels=out_channels,\n",
    "        kernel_sizes=kernel_sizes,\n",
    "        bn=True,\n",
    "        f_map_size=3,\n",
    "        out_dim=latent_dim * 2,\n",
    "    ),\n",
    "    out_dim=latent_dim,\n",
    "    min_var=1e-6,\n",
    ")\n",
    "decoder = GaussianModel(\n",
    "    model=DeCNN(\n",
    "        in_dim=latent_dim,\n",
    "        f_map_size=7,\n",
    "        channel_size=32,\n",
    "        out_channels=rev_out_channels,\n",
    "        kernel_sizes=rev_kernel_sizes,\n",
    "        bn=True,\n",
    "    ),\n",
    "    out_dim=1,\n",
    "    min_var=0.0,\n",
    "    split_dim=1,\n",
    ")\n",
    "vae = GaussianVAE(encoder=encoder, decoder=decoder)\n",
    "vae = vae.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1388aff-b6db-4c01-93c2-2c83a1099144",
   "metadata": {},
   "source": [
    "#### Initializing the optimizer and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eb889b6-0d60-4f70-a9c3-439a364bca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=vae.parameters(), lr=lr)\n",
    "\n",
    "train_args = TrainArgs(\n",
    "    info_vae=info_vae,\n",
    "    num_epochs=num_epochs,\n",
    "    div_annealing=DivAnnealing(\n",
    "        start_epochs=start_epochs,\n",
    "        linear_epochs=linear_epochs,\n",
    "        start_scale=start_scale,\n",
    "        end_scale=end_scale,\n",
    "    ),\n",
    "    print_every=print_every,\n",
    "    eval_every=eval_every,\n",
    "    smoothing=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2255bd7-0aea-4803-94e2-7dda528a02bc",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8dc2a-76f2-46d4-a980-4aa14791cbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | Loss: 182.38063 | Div scale: 0.100\n",
      "NLL: 151.17239 | KL: 312.08234\n",
      "Step: 50 | Loss: 92.97064 | Div scale: 0.100\n",
      "NLL: 85.81812 | KL: 15.60812\n",
      "Step: 100 | Loss: 76.20986 | Div scale: 0.100\n",
      "NLL: 71.40569 | KL: 16.44229\n",
      "Step: 150 | Loss: 64.01343 | Div scale: 0.100\n",
      "NLL: 58.72035 | KL: 22.93576\n",
      "Step: 200 | Loss: 51.30028 | Div scale: 0.100\n",
      "NLL: 47.11209 | KL: 24.04874\n",
      "Step: 250 | Loss: 38.58748 | Div scale: 0.100\n",
      "NLL: 33.78138 | KL: 24.81089\n",
      "Step: 300 | Loss: 31.77712 | Div scale: 0.100\n",
      "NLL: 28.60517 | KL: 24.00307\n",
      "ELBO at the end of epoch #1 is 27.35907\n",
      "Step: 350 | Loss: 29.12336 | Div scale: 0.100\n",
      "NLL: 25.96612 | KL: 24.32596\n",
      "Step: 400 | Loss: 25.81496 | Div scale: 0.100\n",
      "NLL: 22.47495 | KL: 24.46352\n",
      "Step: 450 | Loss: 22.52387 | Div scale: 0.100\n",
      "NLL: 19.93489 | KL: 23.43153\n",
      "Step: 500 | Loss: 21.76904 | Div scale: 0.100\n",
      "NLL: 20.00658 | KL: 23.75232\n",
      "Step: 550 | Loss: 21.85739 | Div scale: 0.100\n",
      "NLL: 19.11955 | KL: 22.24253\n",
      "Step: 600 | Loss: 21.90847 | Div scale: 0.100\n",
      "NLL: 19.68378 | KL: 23.41671\n",
      "Step: 650 | Loss: 21.61189 | Div scale: 0.100\n",
      "NLL: 20.06766 | KL: 22.94263\n",
      "ELBO at the end of epoch #2 is 19.63979\n",
      "Step: 700 | Loss: 21.51109 | Div scale: 0.100\n",
      "NLL: 19.20347 | KL: 22.29056\n",
      "Step: 750 | Loss: 21.65938 | Div scale: 0.100\n",
      "NLL: 19.06200 | KL: 22.04786\n",
      "Step: 800 | Loss: 21.67112 | Div scale: 0.100\n",
      "NLL: 19.62516 | KL: 21.55080\n",
      "Step: 850 | Loss: 21.35992 | Div scale: 0.100\n",
      "NLL: 18.90803 | KL: 22.13559\n",
      "Step: 900 | Loss: 21.80261 | Div scale: 0.100\n",
      "NLL: 19.79439 | KL: 22.05218\n",
      "Step: 950 | Loss: 21.46439 | Div scale: 0.100\n",
      "NLL: 19.15113 | KL: 22.44437\n",
      "ELBO at the end of epoch #3 is 19.87602\n",
      "Step: 1000 | Loss: 21.60241 | Div scale: 0.100\n",
      "NLL: 18.94932 | KL: 22.16248\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    train_data=train_loader,\n",
    "    vae=vae,\n",
    "    optimizer=optimizer,\n",
    "    args=train_args,\n",
    "    eval_data=eval_loader,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9727ff-10dc-4379-b276-3b7f5e19dc64",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d276e-7799-479e-8d3c-112dc66d636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_loader, vae, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d0f2-c413-4dda-9f86-d8f94ef45801",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = next(iter(test_loader))[0][:16].to(device)\n",
    "show(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639453b-d606-4e52-b7df-bc23e82b3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images = vae(input_images)\n",
    "show(reconstructed_images.mu_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
